\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{xcolor}
\usepackage{mathpartir}
\usepackage{url}

% Theorems
\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{remark}[thm]{Remark}
\newtheorem{claim}[thm]{Attempt}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{lemm}{Lemma}


\newenvironment{proofattempt}{\paragraph{\emph{Proof Attempt}.}}{\hfill\color{red}{X}\par}
\newenvironment{prfattemptref}[1]{\paragraph{\emph{Proof Attempt of #1}.}}{\hfill\color{red}{X}\par}

\newcommand{\redprl}{{\color{red}\textbf{Red}}\textbf{PRL}}

\newcommand{\eeq}{\ensuremath{\doteq}}

\newcommand{\hasTF}[2]{\ensuremath{#1 \vdash #2\ \mathsf{type}}}
\newcommand{\hasEF}[3]{\ensuremath{#1 \vdash #2 : #3}}
\newcommand{\hasTEF}[3]{\ensuremath{#1 \vdash #2 \equiv #3\ \mathsf{type}}}
\newcommand{\hasEEF}[4]{\ensuremath{#1 \vdash #2 \equiv #3 : #4}}

\newcommand{\hasTC}[2]{\ensuremath{#1 \gg #2\ \mathsf{type}}}
\newcommand{\hasEC}[3]{\ensuremath{#1 \gg #2 \in #3}}
\newcommand{\hasTEC}[3]{\ensuremath{#1 \gg #2 \eeq #3\ \mathsf{type}}}
\newcommand{\hasEEC}[4]{\ensuremath{#1 \gg #2 \eeq #3 : #4}}

\newcommand{\hasC}[5]{\ensuremath{#1 : (#2 \rhd #3) \leadsto (#4 \rhd #5)}}

\newcommand{\hterm}[2]{\ensuremath{\mathsf{HT}_{#1}(#2)}}
\newcommand{\htermp}[2]{\ensuremath{\mathsf{HT}^+_{#1}(#2)}}
\newcommand{\termb}[1]{\ensuremath{{#1} \; \mathsf{term}_{\beta}}}
\newcommand{\hv}[2]{\ensuremath{\mathsf{HV}_{#1}(#2)}}
\newcommand{\hvcbn}[2]{\ensuremath{\mathsf{HV}^{\mathsf{cbn}}_{#1}(#2)}}
\newcommand{\hvcbv}[2]{\ensuremath{\mathsf{HV}^{\mathsf{cbv}}_{#1}(#2)}}

\newcommand{\contrb}[2]{#1 \mathrel{\text{contr}_\beta} #2}
\newcommand{\bnf}[1]{#1 \mathrel{\text{nf}_\beta}}
\newcommand{\bnorm}[1]{\ensuremath{#1 \mathrel{\text{norm}_\beta}}}
\newcommand{\stepb}[2]{\ensuremath{#1 \mapsto_{\beta} #2}}
\newcommand{\stepbs}[2]{\ensuremath{#1 \mapsto_{\beta}^* #2}}
\newcommand{\stepbk}[3]{\ensuremath{#1 \mapsto_{\beta}^{(#2)} #3}}

\newcommand{\hnorm}[3]{\ensuremath{\mathsf{HN}^{#1}_{#2}(#3)}}
\newcommand{\id}[1]{\ensuremath{\mathsf{id}(#1)}}

\newcommand{\AND}{\mathrel{\wedge}}
\newcommand{\OR}{\mathrel{\vee}}

\newcommand{\step}[2]{\ensuremath{#1 \mapsto #2}}
\newcommand{\steps}[2]{\ensuremath{#1 \mapsto^* #2}}
\newcommand{\eval}[2]{\ensuremath{#1 \mathrel{\Downarrow} #2}}
\newcommand{\valueJ}[1]{\ensuremath{#1\ \mathsf{value}}}
\newcommand{\fillin}[2]{\ensuremath{#1\{#2\}}}

\newcommand{\fn}[2]{\ensuremath{#1 \to #2}}
\newcommand{\nat}{\ensuremath{\mathsf{nat}}}
\newcommand{\bool}{\ensuremath{\mathsf{bool}}}
\newcommand{\tp}{\ensuremath{\mathsf{T}}}
\newcommand{\ap}[2]{\ensuremath{#1\ #2}}
\newcommand{\lam}[3]{\ensuremath{\lambda #1 {:} #2.\, #3}}

\newcommand{\E}{\mathcal{E}}

% Page layout
\usepackage[paper=letterpaper,top=1in,bottom=1in,left=0.8in,right=0.8in,]{geometry}
\setlength{\parindent}{0mm}
\setlength{\parskip}{1.5mm}

\usepackage{fancyhdr}
\fancyhead[RO,LE]{\scshape 15-819: Computational Higher Type Theory}
\fancyhead[LO,RE]{\scshape Lecture Notes Week 2}
\pagestyle{fancy}

\usepackage{hyperref}

% titles
\usepackage{titlesec}
\titleformat*{\section}{\large\bfseries}
\titleformat*{\subsection}{\normalsize\bfseries}
\titleformat*{\subsubsection}{\bfseries}
\titleformat*{\paragraph}{\bfseries}

% package to customize three basic list environments: enumerate, itemize and description.
\usepackage{enumitem}
\setitemize{noitemsep, topsep=0pt, leftmargin=*}
\setenumerate{noitemsep, topsep=0pt, leftmargin=*}
\setdescription{noitemsep, topsep=0pt, leftmargin=*}

% to dos
\usepackage{todonotes}

\begin{document}

\begin{center}
\Large{\scshape Computational Higher Type Theory (CHTT)}\\[2pt]
\large{\scshape Robert Harper}\\[4pt]
\large\bfseries{Lecture Notes of Week 2 by Stephanie Balzer and Yue Niu}
\end{center}

\bigskip

\section{Setting the Scene}

Last week, we explored \emph{closed term computation} for the simply typed lambda calculus
(STLC) with the goal to prove that all well-typed STLC programs terminate.  Our exploration
lead us to rediscover Tait's~\citeyear{Tait:67} \emph{hereditary termination} $\hterm{A}{M}$ of
a term $M$ at type $A$ and \emph{hereditary terminating substitution} $\hterm{\Gamma}{\gamma}$
of closing substitution mapping $\gamma$ at context $\Gamma$ to strengthen our inductive
hypothesis.  The predicates $\hterm{A}{M}$ and $\hterm{\Gamma}{\gamma}$ amount to
\emph{behavioral} invariants, indexed by a type and typing context, respectively.  Depending on
the source, different terms are used in the literature to refer to methods based on such
behavioral invariants.  Most commonly used is the term \emph{hereditary}.  Tait himself used
the term \emph{computability}, whereas some people refer to such methods as \emph{Tait's
  Method}.  Statman~\citeyear{Statman:85} introduced the term \emph{logical relation}, which
underlines the idea of a behavioral invariant.  Moreover, the term \emph{Girard's method} can
be found in the literature as well as the term \emph{Reducibility Method}, which is most likely
due to Girard himself.

In this week's lectures, we are going to generalize the results of the previous week to
\emph{open term computation}.  Before doing so, however, we first have to finish our proof of
hereditary termination.

\section{Closed Term Computation Continued}

Our main result of last week is the proof or Theorem~\ref{thm:hterm}, which states that well-typed terms are hereditarily terminating under substitution by 
hereditarily terminating maps:

\begin{thm}[Hereditary termination]\label{thm:hterm}
  If $\hasEF{\Gamma}{M}{A}$ and $\gamma : \cdot \to \Gamma$ so that
  $\hterm{\Gamma}{\gamma}$ then $\hterm{A}{\hat{\gamma}(M)}$.
\end{thm}

Given this result, we should move on to proving that hereditary termination actually implies
termination.  Before doing so, however, we first have to finish our proof
Theorem~\ref{thm:hterm}, which relies on a lemma known as \emph{head expansion} or
\emph{reverse execution}, which we are going to prove next:

\begin{lem}[Head expansion]\label{lem:hexp}
  If $\hterm{A}{M'}$ and $\step{M}{M'}$ then $\hterm{A}{M}$.
\end{lem}

\begin{proof}
  By induction on the structure of $A$.
  \begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
    Suppose $\hterm{b}{M'}$ and $\step{M}{M'}$. We need to show $\hterm{b}{M}$. By the
    definition of hereditary termination, it suffices to show that $M \Downarrow$. 
    This is clear since $M' \Downarrow$ and $\step{M}{M'}$.
  \item $A = \fn{A_1}{A_2}$\\
    Suppose $\hterm{\fn{A_1}{A_2}}{M'}$ and $\step{M}{M'}$. We need to show $\hterm{\fn{A_1}{A_2}}{M}$.
    Now suppose $\hterm{A_1}{N}$, and we need to show $\hterm{A_2}{\ap{M}{N}}$. 
    By the definition of hereditary termination and by our assumption, we have $\hterm{A_2}{\ap{M'}{N}}$. 
    Note that $\step{\ap{M}{N}}{\ap{M'}{N}}$ by our assumption and the compuation rule.
    Now applying the IH\footnote{Note that the IH can be applied because the induction is on
      the structure of $A$, not on terms.  Whereas the terms in the hereditary termination
      predicate get bigger, the types get smaller.}, we have $\hterm{A_2}{\ap{M}{N}}$.
    \qedhere
  \end{itemize}
\end{proof}

Let's now return to proving our ultimate goal, namely that hereditary termination implies termination of terms in the STLC:

\begin{thm}[Termination]\label{thm:term}
  If $\hterm{A}{M}$ then $\termb{M}$.
\end{thm}

\begin{proofattempt}
  By induction on the structure of $A$.
   \begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
    Suppose $\hterm{b}{M}$. Done by definition of hereditary termination.  
  \item $A = \fn{A_1}{A_2}$\\
    Suppose $\hterm{\fn{A_1}{A_2}}{M}$. We need to show $\termb{M}$. We are stuck here.
  \end{itemize}
\end{proofattempt}

The question is what we should do at this point.  One possibility is to basically ``give up''
and weaken the theorem to expect termination to hold only for observables, i.e., for terms of
the base type.  Alternatively, we could strengthen the induction hypothesis even further by
changing the defintion of $\hterm{A}{M}$ to also insist on $\termb{M}$.

Another option is to change the definition of hereditary termination entirely and use a
\emph{positive} formulation rather than a \emph{negative} one.  Whereas our current negative
formulation is phrased in terms of an implication, the positive formulation requires the term
to be an actual lambda.  \emph{Positive hereditary termination} $\htermp{A}{M}$ of a term $M$ at type
$A$ is defined as follows:

\begin{align*}
  \htermp{b}{M} &\triangleq \steps{M}{c} \quad (\exists c : b)\\
  \htermp{\fn{A}{B}}{M} &\triangleq \steps{M}{\lam{x}{A}{M_2}} \; \text{and}\;
  \forall M_1.\ \htermp{A}{M_1} \implies \htermp{A_2}{[M_1/x]M_2}
\end{align*}

The positive formulation is also known as the \emph{method of canonical forms}.  Using a
positive formulation of hereditary termination, the proof of the introductory rule is
straightforward, whereas the elimination rule takes some work, relying on head expansion, in
particular.

We can rephrase the above definition of $\htermp{A}{M}$ by introducing the notion of a
\emph{hereditary value} $\hv{A}{V}$ of a value $V$ at type $A$

\begin{align*}
  \htermp{b}{M} &\triangleq \steps{M}{\valueJ{V}} \;\text{such that}\; \hv{A}{V}
\end{align*}

\noindent and then give a definition of a hereditary value that differs depending on whether a \emph{call-by-value}
($\mathsf{cbv}$) or \emph{call-by-name} ($\mathsf{cbn}$) semantics is used:

\begin{align*}
\hv{b}{V} &\triangleq V = c : b \\
\hvcbv{\fn{A_1}{A_2}}{V} &\triangleq V = \lam{x}{A}{M_2} \; \text{and} \; \forall V_1. \hvcbv{A_1}{V_1} \implies
\hterm{A_2}{[V_1/x]M_2} \\
\hvcbn{\fn{A_1}{A_2}}{V} &\triangleq V = \lam{x}{A}{M_2} \; \text{and} \; \forall M_1. \hterm{A_1}{M_1} \implies
\hterm{A_2}{[M_1/x]M_2}
\end{align*}

In both interpretations a hereditary value at a base type is simply a value, whereas at a
function type the insistance on a value as an argument is only made for a call-by-value
semantics, but not for a call-by-name semantics.  From this perspective, the negative
formulation of hereditary termination only really makes sense in the context of a call-by-name
semantics.  Only then, function arguments can be unevaluated computations that permit the weakened
termination theorem discussed earlier that insists on termination for base types only.  For a
call-by-value semantics, on the other hand, a positive formulation of hereditary termination is
required for termination, as this formulation is phrased in terms of values.

In this case study of closed term computation we have assumed a call-by-name evaluation
semantics.  For a call-by-value evaluation semantics, our main fundamental
Theorem~\ref{thm:hterm} needs to be phrased in terms of hereditary values, with
$\hvcbv{\Gamma}{\gamma}$ correspondingly defined:

\begin{thm}[Call-by-value hereditary termination]\label{thm:hcbvterm}
  If $\hasEF{\Gamma}{M}{A}$ and $\gamma : \cdot \to \Gamma$ so that
  $\hvcbv{\Gamma}{\gamma}$ then $\htermp{A}{\hat{\gamma}(M)}$.
\end{thm}

\subsection{Summary}

The introduction of behavioral invariants has allowed us to express the \emph{semantic}
property of \emph{syntax}.  Specifically, we have shown that well-type terms terminate.  To
talk about the semantic properties of terms, we introduce the following notation:

\begin{align*}
&A \; \mathsf{type} &&\text{iff}  \quad \quad A, B ::= b \mid \fn{A}{B}&\\
&\gamma \in \Gamma &&\text{iff} \quad \quad \hterm{\Gamma}{\gamma}&\\
&M \in A &&\text{iff} \quad \quad \hterm{A}{M}&\\
&\hasEC{\Gamma}{M}{A} &&\text{iff} \quad \quad \gamma \in \Gamma \implies \hat\gamma(M) \in A&
\end{align*}

Note that the ``membership'' relation has a computational flavor; it is a behavorial condition
on $M$ (or $\gamma$), which says that $M$ (or $\gamma$) satisfies the specification $A$ (or
$\Gamma$).

Now, we can state our main fundamental Theorem~\ref{thm:hterm} as follows:

\begin{thm}[Hereditary termination -- semantic formulation]
If $\hasEF{\Gamma}{M}{A}$, then $\hasEC{\Gamma}{M}{A}$.
\end{thm}

This is in some sense a soundness theorem (in the language of formal logics), which means that
the formally derivable terms are actually true (according to the computational
specification). Therefore, we can think of formal systems as a way of \emph{accessing} the
\emph{truth}. Note that we make no claims that $\hasEC{\Gamma}{M}{A}$ be decidable, as it is
fruitless to expect the truth to be decidable in general. \footnote{See Derek Dreyer's Milner
  Award Lecture for further discussion.}

\section{Open Term Computation}

Next, we move on to \emph{open term computation}, for which we would like to prove
\emph{normalization}.  In this new setting, we interpret the judgment $\hasEF{\Gamma}{M}{A}$ as
a mapping on open terms --- rather than a mapping on closed terms, as we have done previously.
In this setting, we adopt a computational view on variables, treating them as indeterminates.

A term $M$ is \emph{normalizing}, $\bnorm{M}$, if it has some terminating sequence of
beta-reductions.  Recall the beta-contraction relation, $\contrb{P}{P'}$:
\[
\contrb{\ap{(\lam{x}{A}{M})}{N}}{[N/x]M}
\]

Relying on beta-contraction, we formulate beta-reduction by the following rules:

\begin{mathpar}
\inferrule{
  \contrb{M}{N}
}{
  \stepb{M}{N}
} \and
\inferrule{
  \stepb{M}{M'}
}{
  \stepb{\ap{M}{N}}{\ap{M'}{N}}
} \and
\inferrule{
  \stepb{N}{N'}
}{
  \stepb{\ap{M}{N}}{\ap{M}{N'}}
} \and
\inferrule{
  \stepb{M}{M'}
}{
  \stepb{\lam{x}{A}{M}}{\lam{x}{A}{M'}}
} 
\end{mathpar}

Further, we define beta-normal form, $\bnf{N}$:
\[
\bnf{N} \triangleq N \not\mapsto_{\beta}
\]

Where $N \not\mapsto_{\beta}$ means that no beta-reduction rule applies to $N$.  Finally, we
can define when a term is beta-normalizing, $\bnorm{M}$:
\[
\bnorm{M} \triangleq \exists N. \stepbs{M}{N} \;\text{and}\; \bnf{N}
\]

Now we can state the fundamental theorem for normalization: 
\begin{thm}[Normalization]\label{thm:norm}
If $\hasEF{\Gamma}{M}{A}$ then $\bnorm{M}$.
\end{thm}

Attempting to prove Theorem~\ref{thm:norm} by induction on typing, we will get stuck on proving
the case of function application, as we already did when attempting to prove termination last
week.  Similarly, we introduce a stronger notion for normalization, \emph{hereditary normalization}:

\begin{align*}
  \hnorm{\Delta}{b}{M} &\triangleq \bnorm{M}\\
  \hnorm{\Delta}{\fn{A}{B}}{M} &\triangleq
  \forall N.\ \hnorm{\Delta}{A}{N} \implies \hnorm{\Delta}{B}{\ap{M}{N}}
\end{align*}

The above definition relies on \emph{hereditary normalizing substitution}, which generalizes
hereditary terminating substitution to open terms:
\[
\hnorm{\Delta}{\Gamma}{\gamma} \triangleq \forall x : A \in \Gamma.\ \hnorm{\Delta}{A}{\gamma(x)}
\]
As before, $\gamma$ defines the mapping $\gamma : \Delta \to \Gamma$ such that for each
$x : A \in \Gamma$ we have $\hasEF{\Delta}{\gamma(x)}{A}$.  The superscript $\Delta$ in
$\hnorm{\Delta}{\Gamma}{\gamma}$ draws attention to the fact that open terms can be substituted
for variables, contrasting hereditary terminating substitution $\hterm{\Gamma}{\gamma}$, where
$\Delta$ is empty.  Recall that $\hat{\gamma}(M)$, or $\hat{M}$, for short, denotes the application
of substitution to the term $M$, which is defined for our language as follows:

\begin{align*}
\hat{\gamma}(c) &\triangleq c\\
\hat{\gamma}(x) &\triangleq \gamma(x)\\
\hat{\gamma}(M N) &\triangleq \hat{\gamma}(M) \hat{\gamma}(N)\\
\hat{\gamma}(\lam{x}{A}{M}) &\triangleq \lam{x}{A}{\hat{\gamma}(M)} \quad (x \notin \mathsf{dom}\; \gamma)
\end{align*}

Given the definitions of $\hnorm{\Delta}{A}{M}$ and $\hnorm{\Delta}{\Gamma}{\gamma}$ we can now
state our fundamental theorem of normalization:

\begin{thm}[Hereditary normalization]\label{thm:hnorm}
If $\hasEF{\Gamma}{M}{A}$ and $\hnorm{\Delta}{\Gamma}{\gamma}$, then $\hnorm{\Delta}{A}{\hat\gamma(M)}$.
\end{thm}

Our fundamental theorem uses a negative formulation of hereditary normalization, which is the
only possible choice in the presence of indeterminates.  This raises the question what how to
accommodate positive types, such as sums.

To prove normalization for the simply typed lambda calculus, we additionally need the following
two lemmas, whose proofs mutually rely on each other:

\begin{lem}\label{l2}
If $\hnorm{\Delta}{A}{M}$ then $\bnorm{M}$.
\end{lem}

\begin{lem}\label{l3}
$\hnorm{\Gamma}{\Gamma}{\id{\Gamma}}$.
\end{lem}

In the following, we develop the proof of our fundamental Theorem~\ref{thm:hnorm} and the two
lemmas above.  As usual, we develop the proof step-by-step, starting with failed attempts that
lead us to refine what we have already stated.

\subsection{Proving Normalization}

\subsubsection{Proof of Fundamental Theorem}

\begin{proof}[\textbf{Proof of Theorem~\ref{thm:hnorm}}]
By induction on typing. 
\begin{itemize}
  \setlength\itemsep{1em}
  \item $\hasEF{\Gamma', x : A}{x}{A}$\\
    Suppose $\hnorm{\Delta}{\Gamma', x : A}{\gamma}$. 
    We need to  show $\hnorm{\Delta}{A}{\hat{\gamma}(x)}$, which follows directly from our assumption.
  \item $\hasEF{\Gamma}{c}{b}$\\
    Suppose $\hnorm{\Delta}{\Gamma}{\gamma}$. We need to show that $\hnorm{\Delta}{b}{c}$, which is to 
    show that $\bnorm{c}$. Since $\bnf{c}$, we have $c$ normalizing in 0 steps. 
  \item $\inferrule{
      \hasEF{\Gamma}{M}{\fn{A}{B}}\\
      \hasEF{\Gamma}{N}{A}
    }{\hasEF{\Gamma}{\ap{M}{N}}{B}}$\\
    Applying the IH, we have $\hnorm{\Delta}{\fn{A}{B}}{\hat{\gamma}(M)}$
    and $\hnorm{\Delta}{A}{\hat{\gamma}(N)}$. By definition of hereditary normalization, we have
    $\hnorm{\Delta}{B}{\ap{\hat{\gamma}(M)}{\hat{\gamma}(N)}}$. Since $\hat{\gamma}(\ap{M}{N}) = 
    \ap{\hat{\gamma}(M)}{\hat{\gamma}(N)}$, we have
    $\hnorm{\Delta}{B}{\hat{\gamma}(\ap{M}{N})}$.
  \item
    $\inferrule{
      \hasEF{\Gamma, x : A}{M}{B}\\
    }{\hasEF{\Gamma}{\lam{x}{A}{M}}{\fn{A}{B}}}$\\
    Suppose $\hnorm{\Delta}{\Gamma}{\gamma}$. We need to show that 
    $\hnorm{\Delta}{\fn{A}{B}}{\hat{\gamma}(\lam{x}{A}{M})}$. 
    Thus, suppose $\hnorm{\Delta}{A}{N}$. It suffices to show that 
    $\hnorm{\Delta}{B}{\ap{\hat{\gamma}(\lam{x}{A}{M})}{N}}$. Notice that with $N$, we can extend $\gamma$ to be
    $\gamma' = \gamma[x \mapsto N]$, and since $N$ is hereditarily normalizing at $A$, it follows that 
    $\hnorm{\Delta}{\Gamma,x : A}{\gamma'}$. Applying the IH, we have that $\hnorm{\Delta}{B}{\hat{\gamma'}(M)}$. 
    Since substitution is commutative, $\hat{\gamma'}(M) = [N/x]\hat{\gamma}(M)$, and 
    $\ap{\hat{\gamma}(\lam{x}{A}{M})}{N} = \ap{\lam{x}{A}{\hat{\gamma}(M)}}{N}$. Further, 
    $\step{\ap{\lam{x}{A}{\hat{\gamma}(M)}}{N}}{[N/x]\hat{\gamma}(M)}$ by the computation rule. The result then follows
    from head expansion. 
   \qedhere
\end{itemize}
\end{proof}

\subsubsection{Attempts at Proving Lemmas \ref{l2} and \ref{l3}}

The proof of Lemmas \ref{l2} and \ref{l3} goes by simultaneous induction.  It will turn out that
we will need to further strengthen Lemma \ref{l3} in order to get the induction go through, but
let's see first where we fail.

\begin{prfattemptref}{Lemma~\ref{l2}}
By induction on the structure of $A$.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
  Immediate from definition of hereditary normalization.
\item $A = \fn{A_1}{A_2}$\\
  Suppose $\hnorm{\Delta}{A}{M}$. We need to show $\bnorm{M}$. Now we are in a bind. If we can
  somehow use Lemma \ref{l3} to obtain a hereditarily normalizing input of type $A_1$, then we
  could apply the inductive hypothesis to possibly obtain the result. For now, we will
  assume that there is a way to create a context $\Gamma'$ such that $x : A_1 \in \Gamma'$ (see
  Section~\ref{sec:kripke_sem} for solution).  By Lemma \ref{l3} we have
  $\hnorm{\Gamma'}{\Gamma'}{\id{\Gamma'}}$, in particular, $\hnorm{\Gamma'}{A_1}{x}$. By the
  definition of hereditary normalization, we further have that
  $\hnorm{\Gamma'}{A_2}{\ap{M}{x}}$. Now applying the IH, we see that $\bnorm{\ap{M}{x}}$, and
  by Lemma~\ref{l6} we have $\bnorm{M}$.  \qedhere
\end{itemize}
\end{prfattemptref}

Postponing the issues with this proof, we will move on to proving Lemma \ref{l3}, and resolve everything after
presenting the two proofs.

\begin{prfattemptref}{Lemma~\ref{l3}}
Let $x : A \in \Gamma$ be arbitrary. Proceed by induction on the structure of $A$.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
  We need to show $\hnorm{\Gamma}{b}{x}$, which holds since $\bnf{x}$.
  \item $A = \fn{A_1}{A_2}$\\
  We need to show $\hnorm{\Gamma}{\fn{A_1}{A_2}}{x}$. Suppose $\hnorm{\Gamma}{A_1}{M_1}$, and it suffices to show
  that $\hnorm{\Gamma}{A_2}{\ap{x}{M_1}}$. Now it would be nice to apply the IH to complete the proof, which
  is unfortunately not strong enough.
\end{itemize}
\end{prfattemptref}

If we knew that a variable of a function type is hereditarily normalizing when applied to a
beta-normal term, we could complete the above proof.  So, let's refine Lemma~\ref{l3} with
this idea, resulting in Lemma~\ref{l4}:

\begin{lem}\label{l4}
For all $k$, if $x : A_1 \to \dots \to A_k \to A \in \Gamma$ and for each $i \le k$, $\hasEF{\Gamma}{M_i}{A_i}$ and $\bnorm{M_i}$, then $\hnorm{\Gamma}{A}{\ap{\ap{x}{M_1}}{\dots M_k}}$.
\end{lem}

Note that we need each argument to be \emph{normalizing} instead of merely \emph{hereditarily
  normalizing}.  Before proving Lemma \ref{l4}, we first return to the issue raised in the
proof of Lemma~\ref{l2}.

\subsubsection{Resolving Issues with Kripke Semantics}\label{sec:kripke_sem}

In the proof of Lemma~\ref{l2}, we have assumed that we can create a context $\Gamma'$ out of
thin air, which allowed us to supply the argument to the function term.  For this to be indeed
the case, we need a mechanism to \emph{allocate} a fresh variable.  Once we have such a
mechanism, however, the question comes up whether hereditary normalization is \emph{stable}
under such context extensions.  To guarantee that this is indeed the case, we change the
definition of hereditary normalization to make use of the notion of a \emph{Kripke} semantics.
If we think of the typing context as a model of the ``world'', then Kripke semantics suggests
that we can stipulate hereditary normalization to hold in all context extensions, or ``future
worlds''. Viewed logically, this would be the admissibility of weakening with respect to
hereditary normalization.

Thus for our definition of hereditary normalization, we change the higher order terms to expect
``world extensions'':

\[
\hnorm{\Delta}{\fn{A_1}{A_2}}{M} \triangleq \;\text{if}\; \Delta' \ge \Delta \;\text{and}\; \hnorm{\Delta'}{A_1}{M_1}
\;\text{then}\; \hnorm{\Delta'}{A_2}{\ap{M}{M_1}}
\]

Note that $\ge$ is a pre-order on contexts $\Delta$, and thus is reflexive and transitive.  In
general, we get the following \emph{monotonicity} guarantee:

\begin{remark}[Monotonicity]
If $\hnorm{\Delta}{A}{M}$ and $\Delta' \ge \Delta$, then $\hnorm{\Delta'}{A}{M}$.
\end{remark}

We now return to proving our lemmas, accounting for the new definition of hereditary
normalization.  The proof of our main fundamental theorem remains valid.

\subsubsection{Proofs of Lemmas \ref{l2} and \ref{l4}}

\begin{proof}[Proof of Lemma~\ref{l2}]
By induction on the structure of $A$, simultaneously with the proof of Lemma~\ref{l4}.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
  Immediate from definition of hereditary normalization.
  \item $A = \fn{A_1}{A_2}$\\
  Suppose $\hnorm{\Delta}{A}{M}$. We need to show $\bnorm{M}$. Let $\Delta' = \Delta, x : A_1$. By IH on Lemma \ref{l4} 
  (with $k = 0$), we have $\hnorm{\Delta'}{A_1}{x}$. By the definition of hereditary termination, we have 
  $\hnorm{\Delta'}{A_2}{\ap{M}{x}}$. Applying the IH, we have $\bnorm{\ap{M}{x}}$, and by Lemma \ref{l6} we have 
  $\bnorm{M}$. 
  \qedhere
\end{itemize}
\end{proof}

\begin{proof}[Proof of Lemma~\ref{l4}]
By induction on the structure of $A$, simultaneously with the proof of Lemma~\ref{l2}.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
  We need to show $\bnorm{\ap{\ap{x}{M_1}}{\dots M_k}}$, which holds since each $M_i$ is normalizing, and thus the 
  term does not beta-reduce.
  \item $A = \fn{A_{k+1}}{A_{k+2}}$\\
  We need to show $\hnorm{\Gamma}{A}{\ap{\ap{x}{M_1}}{\dots M_k}}$. Let $\Gamma' \ge \Gamma$ and 
  $\hnorm{\Gamma'}{A_{k+1}}{M_{k+1}}$. It suffices to show that 
  $\hnorm{\Gamma'}{A_{k+2}}{\ap{\ap{\ap{x}{M_1}}{\dots M_k}}{M_{k+1}}}$.
  By IH on Lemma \ref{l2}, we have that $\bnorm{M_{k+1}}$, and we obtain the result by applying the IH with $k + 1$.
\end{itemize}
\end{proof}

Finally, we have to state and prove Lemma~\ref{l6}, which we relied upon in the proofs of
Lemmas \ref{l2} and \ref{l4}:

\begin{lem}\label{l6}
If \bnorm{\ap{M}{x}}, then \bnorm{M}.
\end{lem}

\begin{proof}
Let $\stepbs{\ap{M}{x}}{N}$ and $\bnf{N}$.
Proceed with induction on the length of the sequence to beta-normal form.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $\stepbk{\ap{M}{x}}{0}{N}$\\
  Then $\bnf{\ap{M}{x}}$, and $\bnf{M}$, and $M$ also beta-normalizes in 0 steps. 
  \item $\stepbk{\ap{M}{x}}{k+1}{N}$\\
  Proceed by cases on the first step.
  \begin{itemize}
  \setlength\itemsep{1em}
  \item \stepb{\ap{\lam{x}{a}{M'}}{x}}{M'}\\
  Then $M'$ beta-normalizes in $k$ steps. The same $k$ steps will also normalize $M$ performed under the lambda.
  \item \stepb{\ap{M}{x}}{\ap{M'}{x}}\\
  By IH, \bnorm{M'}, and it follows that $\bnorm{M}$.
  \item \stepb{\ap{M}{x}}{\ap{M'}{N}}\\
  Impossible.
  \item \stepb{\lam{x}{A}{M'}}{\lam{x}{A}{M''}}\\
  Impossible.
  \end{itemize}
  
\end{itemize}
\end{proof}

\subsection{Remarks}

We conclude these notes with providing a restatement of Lemma~\ref{l4} using evaluation
contexts and a note on strong normalization.

\subsubsection{Lemma \ref{l4} with evaluation context}

Recall the definition of evaluation contexts: 

\[
  \E ::= \cdot \mid \ap{\E}{M}
\]

We now further characterize evaluation contexts as mappings between types, as detailed in
Chapter~46 of~\cite{HarperBook2016}: 
\begin{mathpar}
\inferrule{
}{
  \hasC{\cdot}{\Gamma}{A}{\Gamma}{A}
}\and
\inferrule{
  \hasC{\E}{\Gamma}{A}{\Gamma'}{\fn{A_1}{A_2}}
  \and
  \hasEF{\Gamma}{M}{A_1}
}{
  \hasC{\ap{\E}{M}}{\Gamma}{A}{\Gamma'}{A_2}
}
\end{mathpar}

Where \hasC{\E}{\Gamma}{A}{\Gamma'}{A'} can be read as if \hasEF{\Gamma}{M}{A}, then \hasEF{\Gamma'}{\fillin{\E}{M}}{A'}.

Further, we can define when evalutaion contexts are beta-normalizing:

\begin{mathpar}
\inferrule{
}{
  \bnorm{\cdot}
}\and
\inferrule{
  \bnorm{M}
  \and
  \bnorm{\E}
}{
  \bnorm{\ap{\E}{M}}
}
\end{mathpar}

Now, Lemma \ref{l4} can be formulated as follows:

\begin{lem}\label{l5}
If \hasC{\E}{\Gamma}{C}{\Gamma}{A} and \bnorm{\E},
then \hnorm{\Gamma, x : C}{A}{\fillin{\E}{x}}
\end{lem}

\begin{proof}
Proceed by induction on the structure of $A$.
\begin{itemize}
  \setlength\itemsep{1em}
  \item $A = b$\\
  Need to show that \hnorm{\Gamma}{b}{x}, which follows since variables are beta-normal.
  \item $A = \fn{A_1}{A_2}$\\
  Proceed with nested induction on context typing and normalization.
  \begin{itemize}
  \setlength\itemsep{1em}
  \item $\E = \cdot$\\
  Let $\Gamma' \ge \Gamma,x:A$. Suppose \hnorm{\Gamma'}{A_1}{M}. It suffices to show \hnorm{\Gamma'}{A_2}{\ap{x}{M}}. 
  Note \bnorm{M} from IH on Lemma \ref{l2}.
  Now apply the outer IH with $\hasC{\ap{\cdot}{M}}{\Gamma}{A}{\Gamma}{A_2}$ to obtain 
  \hnorm{\Gamma,x:A}{A}{\fillin{\ap{\cdot}{M}}{x}}, and result follows from monotonicity of hereditary normalization.
  \item $\E = \ap{\E'}{M}$ because $\hasC{\E'}{\Gamma}{C}{\Gamma}{\fn{A'}{A}}, \hasEF{\Gamma}{M}{A'}$ and 
  \bnorm{M}, \bnorm{\E'}\\
  We need to show that \hnorm{\Gamma,x:C}{A}{\fillin{\E}{x}}. Let $\Gamma' \ge \Gamma,x:C$, and 
  suppose \hnorm{\Gamma'}{A_1}{N}. We need to show \hnorm{\Gamma'}{A_2}{\ap{\fillin{\E}{x}}{N}}. Since
  $\ap{\fillin{\E}{x}}{N} = \fillin{\ap{\E}{N}}{x}$, it suffices to show \hnorm{\Gamma'}{A_2}{\fillin{\ap{\E}{N}}{x}}.
  By the definition of context typing, we have \hasC{\ap{\E}{N}}{\Gamma}{C}{\Gamma}{A_2}. In addition, 
  by IH on Lemma \ref{l2}, we have $\bnorm{N}$, consequently $\bnorm{\ap{\E}{N}}$. Lastly, we obtain the result by applying the outer IH on $\ap{\E}{N}$.
  \end{itemize}
\end{itemize}
\end{proof}

Note that the proof is an induction over the lexicographical ordering on the structures of 
$(A,\; \hasC{\E}{\Gamma}{C}{\Gamma}{C},\; \bnorm{\E})$. In particular, when appealing to the inductive hypothesis,
the size of structurese relating to $\E$ increases in some cases, but only when $A$ is correspondingly decreasing. We can recover Lemma \ref{l4} by instantiating Lemma \ref{l5} with the empty evaluation context.

\subsubsection{Strong Normalization}

In these notes, we have proved normalization for the simply typed lambda calculus.
Occasionally, \emph{strong normalization} is shown to hold for a calculus, which guarantees
that there are no infinite reduction sequences. The value of asserting strong normalization
for a calculus is that it enables reasoning by transfinite induction on reductions, which can be used to prove 
properties such as confluence. 

\bibliographystyle{plainnat}
\bibliography{ctt}

\end{document}
